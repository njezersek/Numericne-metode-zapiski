\input{config.tex}
\begin{document} 

\begin{multicols}{4}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\section{Premična pika}
\[ x = (-1)^S m \cdot b^e\]
\[ m = c_0 + c_1 b^{-1} + c_2 b^{-2} + \dots + c_t b^{-t} \]
\begin{align*}
	S\quad \dots \quad & \text{predznak} \\
	b\quad \dots \quad & \text{baza, ponavadi 2} \\
	m\quad \dots \quad & \text{vrednost mantise} \\
	t\quad \dots \quad & \text{dolžina mantise} \\
	e\quad \dots \quad & \text{vrednost eksponenta $L \leq e \leq U$} \\
	c_i\quad \dots \quad & \text{števke v mejah $0 \leq c_i \leq b-1$} \\
\end{align*}

Sistem premične pike označimo z $P(b, t, L, U)$.

\subsection{Standard IEEE}
Eksponent je zapisan z odmikom:
\[ E = e + \text{odmik}\]
Če je $E=0$, uporabimo \textbf{denormiran zapis}:
\[ x = (-1)^S (c_1 b^{-1} + c_2 b^{-2} + \dots + c_t b^{-t}) \cdot b^{e+1}\]
Sicer pa \textbf{normiran zapis}:
\[ x = (-1)^S (1 + c_1 b^{-1} + c_2 b^{-2} + \dots + c_t b^{-t}) \cdot b^{e}\]

Če so vsi biti eksponenta 1 in vsi biti mantise 0, je $x = (-1)^S \infty$.

Če so vis biti eksponenta 1 in vsi biti mantise niso 0, je $x = \text{NaN}$.

\begin{itemize}
	\item \textbf{Single precision} $b=2$, $t=23$, $L=-126$, $U=127$,
	odmik: 127
	\begin{center}
		\begin{tabular}{ |c|c|c| } 
			\hline
			\textit{predznak} 1 & \textit{exponent} 8 & \textit{mantisa} 23 \\ 
			\hline
		\end{tabular}
	\end{center}
	\item \textbf{Double precision} $b=2$, $t=52$, $L=-1022$, $U=1023$, 
	odmik: 1023
	\begin{center}
		\begin{tabular}{ |c|c|c| } 
		 \hline
		 \textit{predznak} 1 & \textit{exponent} 11 & \textit{mantisa} 52 \\ 
		 \hline
		\end{tabular}
	\end{center}
\end{itemize}

\subsection{Zaokroževanje}
Naj bo $x$ pozitivno število z neskončnim zapisom
\[ x = (c_1 b^{-1} + c_2 b^{-2} + \dots + c_t b^{-t} + c_{t+1} b^{-t-1})  + \dots b^e \]

Kandidata za približek $\text{fl}(x)$ sta:
\begin{align*}
	x_- =&\ (c_1 b^{-1} + c_2 b^{-2} + \dots + c_t b^{-t}) b^e \\
	x_+ =&\ (c_1 b^{-1} + c_2 b^{-2} + \dots + c_t b^{-t} + b^{-t}) b^e
\end{align*}

Vzamemo tistega, ki je bljižje. Če sta enako blizu, izberemo tistega, ki ima zadnjo števko sodo.

\subsubsection{Osnovna zaokrožitvena napaka}
\[ u = \frac{1}{2} b^{-t} \]
\[ \text{fl}(x) = x(1+\delta) \quad \text{za} \quad |\delta| \leq u \]
\[ \frac{|\text{fl}(x) - x|}{|x|} \leq u\]

\section{Napake pri numeričnem računanju}
\begin{itemize}
	\item \textbf{Neodstranljiva napaka} Namesto $x$ imamo približek $\bar{x}$.
	\[ D_n = f(x) - f(\bar{x}) \]
	\item \textbf{Napaka metode} Namesto funkcije $f$ imamo približek $g$.
	\[ D_m = f(\bar{x}) - g(\bar{x})\]
	\item \textbf{Zaokrožitvena napaka} Pri računanju $\tilde{y} = f(\bar{x})$ se pri vsaki operaciji se pojavi zaokrožitvena napaka. Namesto $\tilde{y}$ dobimo $\hat{y}$.
	\[ D_z = \tilde{y} - \hat{y}\]
\end{itemize}

Celotna napaka je $D = |D_n| + |D_m| + |D_z|$.

\subsection{Stopnja občutljivosti}
\textit{Razmerje velikosti spremembe podatkov in spremembe rezultata.}

Naj bo $f: \mathbb{R} \to \mathbb{R}$ zvezno odvedlijva funkcija in $\delta x$ majhna motnja.
\begin{itemize}
	\item \textbf{Absolutna občutljivost} $f$ v točki $x$:
	\[ | f(x + \delta x) - f(x) | \approx |f'(x)| \cdot |\delta x| \]
	\item \textbf{Relativna občutljivost} $f$ v točki $x$:
	\[ \frac{| f(x + \delta x) - f(x) |}{|f(x)|} \approx \frac{|f'(x)| \cdot |\delta x|}{|f(x)|} \]
\end{itemize}

\subsection{Obratna in direktna stabilnost}
\begin{itemize}
	\item \textbf{Direktna stabilnost}: za vsak $x$ direktna napaka ($|f(x) - f(x + \Delta x)|$) majhna (absolutno oz. relativno).
	\item \textbf{Obratna stabilnost}: za vsak $x$ razlika $\Delta x$, ki bi nam dala pravi rezultat majhna.
\end{itemize}

\[ |\text{direktna napaka}| \lesssim \text{občutlijvost} \cdot |\text{obratna napaka}|\]

\section{Nelinearne enačbe}
Iščemo ničle funkcije $f$.
\begin{itemize}
	\item \textbf{Enostavne ničle}: 
	\[f(\alpha) = 0 \quad \text{in} \quad f'(\alpha) \neq 0\]
	\item \textbf{m-kratne ničle}: 
	\[f(\alpha) = f'(\alpha) = \dots = f^{(m-1)}(\alpha) = 0\]
\end{itemize}

\subsection{Občutljivost ničle}
Naj bo $\alpha$  $m$-kratna ničla $\hat{\alpha}$ približek, da je $f(\hat{\alpha}) = \varepsilon$.

Če $f$ razvijemo v Taylorjevo vrsto okoli $\alpha$ in vzamemo prvih $m+1$ členov dobimo:

\begin{align*}
	\varepsilon &\doteq \frac{f^{(m)} (\alpha)}{ m! }(\hat{\alpha} - \alpha )^m &
	|\hat{\alpha} - \alpha| &\doteq \sqrt[m]{\frac{\varepsilon \cdot m!}{|f^{(m)} (\alpha)|}}
\end{align*}


\subsection{Bisekcija}

\begin{koda}[]
vhod: funkcija $f: [a,b] \to \mathbb{R}$, $f(a)f(b) < 0$, natancnost $\varepsilon$
izhod: nicla funkcije $f$

dokler $|b-a| > \varepsilon$:
	$c \leftarrow \frac{a+b}{2}$
	ce $\text{sign}(f(c)) = \text{sign}(f(a))$:
		$a \leftarrow c$
	sicer:
		$b \leftarrow c$
vrni $c$
\end{koda}

$c$ je približek ničle $\alpha$. Velja
\[ |\alpha - c| \leq \frac{b-a}{2^m} \leq \varepsilon\]

Za natančnost $\varepsilon$ potrebujemo  $\log_2 \left( \frac{b-a}{\varepsilon}\right)$ korakov.


\subsection{Navadna iteracija}
Rešujemo $f(x) = 0$. Enačbo pretvorimo v $x = g(x)$. Načinov je veliko:
\begin{itemize}
	\item $g(x) = f(x) + x$
	\item $g(x) = cf(x) + x$
	\item $g(x) = h(x)f(x) + x$ kjer je $h(x)$ funkcija, ki nima ničle v $\alpha$.
\end{itemize}

\subsubsection{Izrek o konvergenci navadne iteracije}
Naj bo $\alpha$ negibna točka za $g$ in naj $g$ na intervalu $[\alpha - d, \alpha + d]$ ($d > 0$)
zadošča Lipschitzovemu pogoju:
\[ \exists m \in [0, 1)\ \forall x,y \in I\ : |g(x) - g(y)| \leq m |x-y| \]
tedaj je $g$ \textit{skrčitev} na $I$.

Potem za vsak $x_0 \in I$ zaporedje $x_{r+1} = g(x_r)$ konvergira k $\alpha$ in velja:
\[ |x_r - \alpha| \leq \frac{m}{1-m} |x_r - x_{r-1}| \]

\textit{Posledica}: Če je $g$ zvezno odvedljiva v $\alpha$ in velja $g'(\alpha) < 1$, obstaja interval $I$, ki vsebuje $\alpha$, da za vsak $x_0 \in I$ zaporedje konvergira k $\alpha$.

\begin{itemize}
	\item Če je $|g'(\alpha)| < 1$, je $\alpha$ \textit{privlačna negibna točka}
	\item Če je $|g'(\alpha)| > 1$, je $\alpha$ \textit{odbojna negibna točka}
\end{itemize}

Če je $\alpha$ odbojna za $g$, je privlačna za $g^{-1}$:\\ $g(x) = x \implies x = g^{-1}(x)$

\subsubsection{Hitrost konvergence}
$p > 0$ je red konvergence, če $\exists C_1, C_2 > 0$, da za vse dovolj pozne člene zaporedja $x_{r+1} = g(x_r)$ velja:
\[ C_1 |x_r - \alpha|^p \leq |x_{r+1} - \alpha| \leq C_2 |x_r - \alpha|^p \]
\textit{Vsak korak se št. decimalk pomnoži s $p$.}

Naj bo $g$ v okolici $\alpha$ $p$-krat zvezno odvedlijva in naj velja 
$g(\alpha) = \alpha$, $g'(\alpha) = \dots = g^{(p-1)}(\alpha) = 0$ in $g^{(p)}(\alpha) \neq 0$.
Tedaj je red konvergence enak $p$.

\subsubsection{Standardni redi konvergence}
\begin{align*}
	p=1 & \quad \dots \quad \text{linearna konvergenca} \\
	p=2 & \quad \dots \quad \text{kvadratična konvergenca}
\end{align*}


\subsection{Tangentna (Newtonova) metoda}
\[ x_{r+1} = x_r - \frac{f(x_r)}{x_r}\]
Red konvergence:
\begin{itemize}
	\item 2, če je $\alpha$ enkratna ničla $f'(\alpha) \neq 0$
	\item 3, če je $f'(\alpha) \neq 0$ in $f''(\alpha) = 0$
	\item 1, če je $\alpha$ večkratna ničla $f'(\alpha) = 0$
\end{itemize}

\subsection{Sekantna metoda}
\[ x_{r+1} = x_r - \frac{f(x_r)}{ \frac{f(x_r)-f(x_{r-1})}{x_r - x_{r-1}} }\]

Red konvergence: $\frac{\sqrt{5}+1}{2} \approx 1.62$

\subsection{Metoda $(f,f',f'')$}
\[ x_{r+1} = x_r - \frac{f(x_r)}{f'(x_r)} - \frac{f''(x_r) f^2(x_r)}{2f'^3(x_r)}\]

Red konvergence: 3 \textit{(pri predpostavkah)}

\subsection{Müllerjeva metoda}
Na $x_r$, $x_{r-1}$, $x_{r-2}$ napnemo parabolo, ničla parabole je naslednji približek.

\[ p(x) = a(x - x_r)^2 + b(x-x_r) + c\]
\[ x_{r+1} = x_r - \frac{2c}{b+\text{sign}(b) \sqrt{b^2-4ac}}\]

\subsection{Hallejeva metoda}
\[ x_{r+1} = x_r - \frac{2 f(x_r) f'(x_r)}{2 f'(x_r)^2 - f(x) f''(x)}\]

\section{Iskanje ničel polinoma}
\[ p_n(x) = a_n x^n + a_{n-1} x^{n-1} + \dots + a_0, \quad a_n \neq 0\]

\subsection{Durand-Kernerjeva metoda}
Naj bodo $z_1, \dots, z_n$ približki za $\alpha_1, \dots, \alpha_n$. 
\[ z_i^{(r+1)} = z_i^{(r)} - \frac{p(z_i^{(r)})}{\prod\limits_{\substack{k=1 \\ k\neq i}}^n (z_i^{(r)} - z_k^{(r)})}\]

\subsection{Metoda pridužene matrike}

\renewcommand*{\arraystretch}{1.5}
\begin{equation*}
	C_{p_n}=\left [
	\begin{array}{*{6}{@{}C{\mycolwd}@{}}}
		0 & 1 &  \dots     & 0  & 0 \\
		& 0 &  &   &  \\
	  \vdots &    & \ddots & & \vdots \\
		&   &        & 1 & 0 \\
		&   &        & 0 & 1 \\
	  -\frac{a_0}{a_n} & -\frac{a_1}{a_n} & \dots & -\frac{a_{n-2}}{a_n} & -\frac{a_{n-1}}{a_n}
	\end{array}
	\right ]
\end{equation*}

Lastne vrednosti (ničle $\det(C-\lambda I)$) matrike $C_{p_n}$ so ravno ničle polinoma $p_n$.

\section{Vektorske in matrične norme}
$\|\cdot \| : \mathbb{R}^n \to \mathbb{R}_+$ je vektorska norma, če
\begin{itemize}
	\item $\| x \| \geq 0$ in $\| x \| = 0 \iff x = 0$
	\item $\| \alpha x \| = |\alpha| \| x \|$, $\alpha \in \mathbb{R}$
	\item $\| x + y \| \leq \| x \| + \| y \|$
\end{itemize}

\begin{align*}
	\| x\|_p &= \sqrt[p]{|x_1|^p + \dots + |x_n|^p} & \dots \quad & p\text{-norma} \\
	\| x \|_\infty &= \max\limits_{1 \leq i \leq n} |x_i| & \dots \quad & \text{max norma}
\end{align*}

Cauchy-Schwartzova neenakost: $|x^T y| \leq \|x\|_2\ \|y\|_2$

$\|\cdot \| : \mathbb{R}^{m \times n} \to \mathbb{R}_+$ je matrična norma, če
\begin{itemize}
	\item $\| A \| \geq 0$ in $\| A \| = 0 \iff A = 0$
	\item $\| \alpha A \| = |\alpha| \| A \|$, $\alpha \in \mathbb{R}$
	\item $\| A + B \| \leq \| A \| + \| B \|$
	\item $\| A  B \| \leq \| A \|  \| B \|$ \textit{submultiplikativnost}
\end{itemize}

\begin{align*}
	\| A \|_1 &= \max_{x\neq 0} \frac{\| Ax\|_1}{\|x\|_1} = \max_{1 \leq j \leq n} \overbrace{\left( \sum_{k=1}^m |a_{kj}| \right)}^{\| a_j\|_1}\\
	\| A \|_2 &= \max_{x\neq 0} \frac{\| Ax\|_2}{\|x\|_2} =\sqrt{\rho (A^T A)} \\
	\| A \|_\infty &= \max_{x\neq 0} \frac{\| Ax\|_\infty}{\|x\|_\infty} = \max\limits_{1 \leq i \leq m} \left( \sum_{k=1}^n |a_{ik}| \right) \\
	\| A \|_F &= \sqrt{\sum_{i,j} a_{ij}^2}\\
	\| A \|_{op} &= \max_{\|c\|_v = 1} || A x ||_v \qquad \textit{$\|\cdot \|_v$ vekt. norma}
\end{align*}

\textbf{spektralni radij} $\rho(A) = \max\{ |\lambda_1|, \dots, |\lambda_n| \}$, kjer so $\lambda$ lastne vrednosti matrike $A$.

Matrična norma $\| \cdot \|_m$ je \textbf{usklajena} z vektorsko normo $\|\cdot \|_v$, če je
\[ \| Ax \|_v \leq \| A \|_m \| x \|_v \]


Na končno dimenzijskih prostorih so vse norme ekvivalentne
\[ \| \cdot \|_\alpha, \| \cdot \|_\beta \implies C_1 \| A \|_\beta \leq \| A \|_\alpha \leq C_2 \| A \|_\beta \]

Za vsako operatorsko normo nad kvadratnimi matrikami velja:
\[ |\lambda | \leq \|A\| \qquad \lambda \text{ lastna vrednost matrike A}\]

\section{Reševanje sistemov linearnih enačb}
Imamo $m$ enačb in $n$ neznank:
\begin{itemize}
	\item $m < n$: \textbf{nedoločen}, $\infty$ rešitev
	\item $m = n$: \textbf{kvadraten}, ponavadi $1$ rešitev
	\item $m > n$: \textbf{predoločen}, ponavadi $0$ rešitev
\end{itemize}

\[ A x = b \qquad A \in \mathbb{R}^{m \times n} \quad b \in \mathbb{R}^m  \quad x \in \mathbb{R}^n\]
\begin{align*}
	\text{Im}A &= \left\{ Ax : x \in \mathbb{R}^n \right\} = \text{Lin}\{a_1, \dots, a_n\} \\
	\text{Ker}A &= \left\{ x \in \mathbb{R}^n : Ax = 0 \right\}
\end{align*}
\[ \text{rang}A = n - \dim (\text{Ker}A)\]

Če je $m=n$, so naslednje izjave ekvivalentne:
\begin{itemize}
	\item $\exists A^{-1}: A^{-1} A = I = A^{-1}A$
	\item $\det(A) \neq 0$
	\item $\text{rang}A = n$
	\item $\text{Ker}A = \{0\}$
\end{itemize}

Lastnosti matrike A:
\begin{align*}
	A = A^T & \quad \dots \quad \text{simetrična} \\
	A = A^H & \quad \dots \quad \text{hermitska} \\
	A^T A = I & \quad \dots \quad \text{ortogonalna}
\end{align*}

\section{LU razcep}
Matriko $A$ zapišemo kot produkt $LU$, kjer je $L$ spodnje trikotna z $1$ na diagonali, $U$ pa zgornje trikotna.

Sistem enačb $Ax = b$ potem rešujemo kot:
\[L(Ux) = b \implies Ly = b \implies Ux = y\]

\subsection{Elementarne eliminacije}
Matriko $A$ množimo z elementarnimi matrikami $L_k$
\[ A^{(k)} = L_{k-1} \dots L_1 A\]

\begin{align*}
	L_k &= I - l_k e_k^T & L_k^{-1} &= I + l_k e_k^T
\end{align*}
\[ l_k = \begin{bmatrix}
	0 &
	\dots &
	0 &
	\frac{a^{(k)}_{k+1, k}}{a^{(k)}_{k, k}} &
	\dots &
	\frac{a^{(k)}_{n, k}}{a^{(k)}_{k, k}}
\end{bmatrix}^T \]
\[ e_k = \begin{bmatrix}
	0 &
	\dots &
	0 &
	1 &
	0 &
	\dots &
	0
\end{bmatrix}^T \]

\[L = L_1^{-1} \dots L_{n-1}^{-1}\]
\[U = L_{n-1} \dots L_1 A\]

Za nesingularno matriko $A \in \mathbb{n\times n}$ obstaja enolični LU razcep $\iff$ vse vodilne podmatrike ($A_k = A(1:k, 1:k)$) nesingularne.

\subsection{LU razcep z delnim pivotiranjem}
Preden dolčimo $L_k$ zamenjamo $k$-to in $\underset{i=k \dots n}{\ \mathrm{argmax}} |a^{(k)}_{k,i}|$-to vrstico matrike $A^{k}$.

\subsection{Občutlivost sistemov linearnih enačb}
\[ \kappa(A) = \| A^{-1} \| \| A \| \quad \text{število občutlivosti}\]
\[ (A + \delta A)(x + \delta x) = (b + \delta b)\]
\[ \frac{\| \delta x \| }{\| x \|} \leq \frac{\kappa(A)}{1-\kappa(A) \frac{\| \delta A \|}{\| A \|}} \left( \frac{\| \delta A \|}{\| A \|} + \frac{\| \delta b \|}{\| b \|} \right)\]

Približno velja $\kappa(A) = 10^e$ $\implies$ relativna napaka rešitve reda $10^{e-16}$

\section{Razcep Choleskega}
Matrika $A$ je \textbf{simetrična pozitivno definitna} (SPD), če je $A = A^T$ in $\forall x \neq 0:\ x^T(Ax) > 0$.

Lastnosti SPD matrik:
\begin{itemize}
	\item vse vodilne podmatrike ($A(1:k, 1:k)$) so SPD
	\item $A([i_1, \dots, i_k], [i_1, \dots, i_k])$, kjer je $1 \leq i_1 < \dots < i_k \leq n$ je SPD
	\item $A$ je SPD $\iff$ vse lastne vrednosti pozitivne
	\item Naj bo $C$ obrnljiva, potem je $CAC^T$ SPD
	\item Če je $A$ SPD, je $A_{ii} > 0$ in $\max\limits_{i,j} |a_{ij}| = a_{kk}$
\end{itemize}

Matrika $A \in \mathbb{R}^{n\times n}, \det A \neq 0$ je SPD $\iff$ obstaja nesingularna spodnje trikotna matrika $V$ s pozitivnimi diagonalnimi elementi, da je $A = VV^T$

\subsection{Algoritem za razcep Cholskega}
Prvi stolpec matrike $V$ izračunamo:
\[
\begin{bmatrix}
	a_{11} \\ \vdots \\ a_{n1}
\end{bmatrix}
=
v_{11} \begin{bmatrix}
	v_{11} \\ \vdots \\ v_{n1}
\end{bmatrix}
\]

$j$-ti stolpec izračunamo:
\[
	\begin{bmatrix}
		a_{1j} \\ a_{2j} \\ \vdots \\ \vdots \\ a_{nj}
	\end{bmatrix}
	=
	v_{j1} \begin{bmatrix}
		v_{11} \\ v_{21} \\ \vdots \\ \vdots \\ v_{n1}
	\end{bmatrix}
	+
	v_{j2} \begin{bmatrix}
		0 \\ v_{22} \\ \vdots \\ \vdots \\ v_{n2}
	\end{bmatrix}
	+ \dots +
	v_{jj} \begin{bmatrix}
		0 \\ \vdots \\ v_{jj} \\ \vdots \\ v_{nj}
	\end{bmatrix}
\]

\begin{koda}
vhod: matrika $A$ z elementi $a_{ij}$
izhod: matrika $V$ z elementi $v_{ij}$
za vsak $j = 1 \dots n$:
	$v_{jj} \leftarrow \sqrt{a_{jj}-\sum\limits_{k=1}^{j-1} v_{jk}^2}$
	za vsak $i = j+1 \dots n$:
		$v_{ij} \leftarrow \frac{1}{v_{jj}} \left( a_{ij} - \sum\limits_{k=1}^{j-1} v_{ik} v_{jk} \right)$
vrni V
\end{koda}

\section{Reševanje sistemov nelinearnih enačb}
$F: \mathbb{R}^n \to \mathbb{R}^n$, $F = (f_1, \dots, f_n)^T$, $x = (x_1, \dots, x_n)^T$ rešujemo $F(x) = 0$

\subsection{Posplošitev navadne iteracije}
$F(x) = 0$ $\implies$ $G(x) = x$
\[ x^{(r+1)} = G(x^{r})\]

\subsubsection{Jakobijeva matrika}
\[
	J_F = \begin{bmatrix}
		\frac{\partial f_1}{\partial x_1} & \dots & \frac{\partial f_1}{\partial x_n} \\
		\vdots & \ddots & \vdots \\
		\frac{\partial f_n}{\partial x_1} & \dots & \frac{\partial f_n}{\partial x_n}
	\end{bmatrix}
\]

Če obstaja odprta množica $\Omega \subseteq \mathbb{R}^n$ z lastnostmi:
\begin{itemize}
	\item $x \in \Omega \implies G(x) \in \Omega$
	\item $x \in \Omega \implies \rho(J_G(x)) \leq q < 1$
\end{itemize}
potem ima $G$ na $\Omega$ natanko eno negibno točko $\alpha$, ki jo dobimo kot:
\[ \lim_{r\to \infty} x^{(r)} \quad \text{za poljuben } x^{(0)} \in \Omega \]

\subsection{Newtnova metoda na več dimenzijah}
\[ G(x) = x - J_F^{-1}(x) F(x) \]

\subsection{Broydenova metoda}
Spremembo $\Delta x$ izračunamo iz enačbe:
\[ B_r \Delta x^{(r)} = -F(x^{(r)})\]
\[ x^{(r+1)} = x^{(r)} + \Delta x^{(x)}\]
\[ B_{r+1} = B_r + \frac{F(x^{(r)})(\Delta x^{(r)})^T}{ (\Delta x^{(r)})^T \Delta x^{(x)}}\]

Za $B_0$ vzamemo $J_F(x^{(0)})$ ali pa kar $I$.

\section{Variacijske metode}
Ekstremi funkcije $G: \mathbb{R}^n \to \mathbb{R}$:

Potreben pogoj za ekstrem je $\nabla G(\alpha) = 0$.

Karakterizacija s Hessejevo matriko:
\[ H_G (\alpha) = \begin{bmatrix}
	\frac{\partial^2 G}{\partial x_i \partial x_j}
\end{bmatrix}_{i,j  = 1}^n
\]
\begin{itemize}
	\item $H_G(\alpha)$ poz. definitna $\implies$ min
	\item $H_G(\alpha)$ neg. definitna $\implies$ max
	\item $H_G(\alpha)$ nedefinitna $\implies$ ni ekstrema
	\item $H_G(\alpha)$ semidefinitna $\implies$ ne vemo
\end{itemize}

\subsection{Metoda za iskanje minimuma}
Naj bo $x^{(r)}$ tekoči približek za minimum.
\[ x^{(r+1)} = x^{(r)} + \lambda_r v_r\]
Izberemo tako smer spusta $v_r$ in velikost koraka $\lambda_r$, da je $G(x^{(r+1)}) < G(x^{(r)})$.
\begin{align*}
	v_r = - \nabla G(x^{(r)}) & \ \dots \ \text{Metoda najhitrejšega spusta}
\end{align*} 
Za določitev $\lambda$ gledamo $g_r(\lambda) = G(x^{(r)} + \lambda v_r)$:
\begin{itemize}
	\item \textit{Največji spust}: $\lambda_r$ je rešitev $g_r'(\lambda) = 0$
	\item \textit{Tangentni spust}: $\lambda_r = \frac{-g_r(0)}{g_r'(0)}$ \\
	Če je $g_r(\lambda_r) > g_r(0)$, razpolavljamo $\lambda_r$, dokler ni $g_r(\lambda_r) < g_r(0)$
\end{itemize}

\section{Metoda najmanjših kvadratov}
\[ A x = b \qquad A \in \mathbb{R}^{m \times n} \quad b \in \mathbb{R}^m \quad x \in \mathbb{R}^n \quad x \gg n\]
Predpostavimo, da je $A$ polnega ranga.
Iščemo rešitev v smislu najmanjših kvadratov:
\[ x^* = \underset{x \in \mathbb{R}^n}{\mathrm{argmin}} \| Ax - b \|_2 \]
Geometrijsko je $x^*$ pravokotna projekcija $b$ na $\text{Im}A$:
\[Ax^* - b\ \bot \ \text{Im}A \iff \forall i:\ a_i^T (Ax^* - b) = 0\]
Rešitev lahko dobimo z \textbf{normalnim sistemom}:
\[ A^T A x^* = A^T b \]

\section{QR razcep}
\[ A \in \mathbb{R}^{m\times n} \quad m > n \quad \text{rang}A = n \]

Obstaja enoličen razcep $A = QR$
\begin{align*}
	Q \in \mathbb{R}^{m\times n} \quad &\text{z ortonormiranimi stolpci} \\
	R \in \mathbb{R}^{n\times n} \quad &\text{zgornje trikotna s poz. diag. el.} \\
\end{align*}

\begin{koda}
za vsak $k = 1, \dots, n$:
	$q_k \leftarrow a_k$
	za vsak $i = 1, \dots, k-1$:
		ce modificiran nacin:
			$r_{ik} \leftarrow q_i^T q_k$
		sicer:
			$r_{ik} \leftarrow q_i^T a_k$
		$q_k \leftarrow q_k - r_{ik} q_i$
	$r_{kk} \leftarrow \| q_k \|_2$
	$q_k \leftarrow \frac{q_k}{r_{kk}}$
\end{koda}

Normalni sistem potem lahko rešimo kot:
\[ A^TAx = A^Tb \implies Rx = Q^Tb\]

\section{Razširjen QR razcep}
\[ A \in \mathbb{R}^{m\times n} \quad m > n \quad \text{rang}A = n \]

\begin{align*}
	Q \in \mathbb{R}^{m\times m} \quad &\text{ortogonalna } \\
	R \in \mathbb{R}^{m\times n} \quad &\text{kvazi zgornje trikotna} \\
\end{align*}

\[ \scriptstyle \min\limits_{x\in\mathbb{R}^n} \| Ax - b\| = \min\limits_{x\in\mathbb{R}^n} \| Q^T(Ax - b)\| = \min\limits_{x\in\mathbb{R}^n} \| Rx - Q^Tb \| \]

\begin{align*}	
	\left\| \underbrace{\begin{bmatrix}
		\tilde{R} \\ 0
	\end{bmatrix}}_{R}
	\begin{bmatrix}
		x
	\end{bmatrix}
	=
	\underbrace{\begin{bmatrix}
		c_1 \\
		c_2
	\end{bmatrix}}_{Q^T b}
	\right\|^2_2
	= \| \tilde{R}x - c_1 \|^2_2 + \|-c_2\|^2_2
\end{align*}
$x^*$ je rešitev $\tilde{R}x = c_1$.

\subsection{Givensove rotacije}
Matriko $A$ množimo z rotacijskimi matrikami $R_{ik}^T$
\[ \underbrace{R_{n,m}^T \dots  R_{n,n+1}^T}_{\text{n. stolpec}} \dots \underbrace{R_{2m}^T \dots R_{23}^T}_{\text{2. stolpec}} \underbrace{R_{1m}^T \dots R_{12}^T}_{\text{1. stolpec}} A = R\]
\[ Q = R_{12} \dots R_{n,m}\]
Naj bo $x = (x_1, \dots, x_m)^T$ enak stolpcu, ki ga želimo popraviti.
\[ r = \sqrt{x_i^2 + x_k^2} \quad c = \frac{x_i}{r} \qquad s = \frac{x_k}{r}\]
Prvi $c$ je na presečišču $i$. vrstice in stolpca, drugi pa na presečišču $k$. vrstice in stolpca.
\[R_{i,k}^T = \begin{bmatrix}   1   & \cdots &    0   & \cdots &    0   & \cdots &    0   \\
	\vdots & \ddots & \vdots &        & \vdots &        & \vdots \\
	   0   & \cdots &    c   & \cdots &   s   & \cdots &    0   \\
	\vdots &        & \vdots & \ddots & \vdots &        & \vdots \\
	   0   & \cdots &    -s   & \cdots &    c   & \cdots &    0   \\
	\vdots &        & \vdots &        & \vdots & \ddots & \vdots \\
	   0   & \cdots &    0   & \cdots &    0   & \cdots &    1
\end{bmatrix}\]

\begin{align*}
	\tilde{R}_{i,k}^T &= \begin{bmatrix}
		c & s \\
		-s & c
	\end{bmatrix} &
	\tilde{R}_{i,k}^T \begin{bmatrix}
		x_i \\ x_k
	\end{bmatrix}
	&=
	\begin{bmatrix}
		r \\ 0
	\end{bmatrix}
\end{align*}
\end{multicols}
\end{document}